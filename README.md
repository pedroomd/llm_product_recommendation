## Technical Assessment

  
### Introduction


This challenge is to build a LLM-based recommendation system that can provide tailored product recommendations by interpreting and responding to user queries, ranging from simple to highly complex scenarios.

### Implementation Details

**The solution to this challenge can be described as follows:**

-   First, a database had to be chosen for this challenge. I decided to go with Neo4j due to the nature of the problem: products are connected to each other when they are bought together. After selecting the database I created a script to ingest the products from the JSON file and the co-occurrences from the Excel. This was handled by the `load_products.py` file. I made sure that each product and relationship is created only once, even if Docker is run multiple times.
    
-   After ingesting the data, the next step was to build an LLM agent. After some research, I discovered that the Langchain community had created this awesome class called [GraphCypherQAChain](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.cypher.GraphCypherQAChain.html), which made my life easier. It can extract the schema of my Neo4j database, generate complex Cypher queries, and execute them. Cool, right? I didn’t  know this existed!
    
-   **The real challenge** was making the system more robust. Imagine a user mentions “Zelda” as the franchise or “Switch” as the console. In such cases, the queries weren’t returning any results because they were filtering or searching for non-existent node names or property values. To handle these situations - and after a lot of reasoning to find the best approach - I ended up relying only on neo4j’s capabilities by creating a full-text index to match products and their properties. While it’s far from perfect, it works most of the time.
    
To evaluate the system I created a JSON file with some prompts. The answers produced by the LLM can be found in the `report.html`. 


### Limitations of the solution

1. The answers produced by the LLM, as shown in the `report.html`, are not set in stone and shouldn't be taken for granted. If I run the `llm.py` script multiple times, the responses may vary. In some runs, a question might be answered incorrectly, while in others, it could be correct. This variability occurs because the answers are heavily dependent on the query generated by the LLM. **This is, without a doubt, a major limitation of this solution**. As expected, I also noticed that using OpenAI's latest reasoning models improves the quality of the generated queries. However, the time it takes to produce a query or answer is also longer. Maybe in a real-world scenario we could consider fine-tuning an LLM with question-query pairs that we know yield good answers. This could help reduce the disparity in queries across different runs.
2. As mentioned before, to make the queries generated by the LLM more robust I introduced a generic `productSearch` full-text index. This index can search across all product types (Game, Console, Accessory) and all properties, allowing fuzzy matching (e.g., `Mario~` → `Mairo`, `Marió`) across the product data. However, this solution is far from ideal. **Using this approach comes with major drawbacks:**
	- It can over-fetch products, resulting in irrelevant matches.
	- Performance-wise, having a single generic index is less efficient than using targeted indexes for specific nodes or properties.
	- The index doesn’t account for semantic understanding.
    
    If I had a bit more time, I would try to have targeted indexes for specific node types and dedicated indexes for critical properties (e.g., `Game.franchise`). I would also consider implementing semantic search by transforming product names and property values into embeddings. This could help map terms like 'family-friendly racing' to relevant games like Mario Kart.

## Usage:

1. Ingest the data into the neo4j database. You will need to configure a .env file with the neo4j url, user and password.

	```bash
	docker compose up --build
	```

2. Install [Poetry](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.cypher.GraphCypherQAChain.html) in your machine, and run:
	```bash
	poetry install --no-root
	```
3. To have the LLM running the evaluation test, run the code like this:
	```bash
	poetry run python llm/llm.py 
	```
